{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aCps12CNglFF"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range, input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Recommender_Systems/archive.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMg83P47kyeK",
        "outputId": "6f4b232f-c642-4a6a-d56b-dd18d96fff97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Recommender_Systems/archive.zip\n",
            "  inflating: genome_scores.csv       \n",
            "  inflating: genome_tags.csv         \n",
            "  inflating: link.csv                \n",
            "  inflating: movie.csv               \n",
            "  inflating: rating.csv              \n",
            "  inflating: tag.csv                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/rating.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cO1KY4UrjW4-",
        "outputId": "fd629e55-3365-482a-d025-c5263f6fd0e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          userId  movieId  rating            timestamp\n",
              "0              1        2     3.5  2005-04-02 23:53:47\n",
              "1              1       29     3.5  2005-04-02 23:31:16\n",
              "2              1       32     3.5  2005-04-02 23:33:39\n",
              "3              1       47     3.5  2005-04-02 23:32:07\n",
              "4              1       50     3.5  2005-04-02 23:29:40\n",
              "...          ...      ...     ...                  ...\n",
              "20000258  138493    68954     4.5  2009-11-13 15:42:00\n",
              "20000259  138493    69526     4.5  2009-12-03 18:31:48\n",
              "20000260  138493    69644     3.0  2009-12-07 18:10:57\n",
              "20000261  138493    70286     5.0  2009-11-13 15:42:24\n",
              "20000262  138493    71619     2.5  2009-10-17 20:25:36\n",
              "\n",
              "[20000263 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5e19ac0-6444-4d04-9337-2a7b94cf14bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000258</th>\n",
              "      <td>138493</td>\n",
              "      <td>68954</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-11-13 15:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000259</th>\n",
              "      <td>138493</td>\n",
              "      <td>69526</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-12-03 18:31:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000260</th>\n",
              "      <td>138493</td>\n",
              "      <td>69644</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2009-12-07 18:10:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000261</th>\n",
              "      <td>138493</td>\n",
              "      <td>70286</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2009-11-13 15:42:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000262</th>\n",
              "      <td>138493</td>\n",
              "      <td>71619</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2009-10-17 20:25:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000263 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5e19ac0-6444-4d04-9337-2a7b94cf14bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5e19ac0-6444-4d04-9337-2a7b94cf14bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5e19ac0-6444-4d04-9337-2a7b94cf14bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make the user ids go from 0...N-1\n",
        "df.userId = df.userId - 1"
      ],
      "metadata": {
        "id": "YIl3tldtke9l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping for movie ids\n",
        "unique_movie_ids = set(df.movieId.values)\n",
        "movie2idx = {}\n",
        "count = 0\n",
        "for movie_id in unique_movie_ids:\n",
        "  movie2idx[movie_id] = count\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "LAF-W7e7lNgh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrXu-icQlfEx",
        "outputId": "e89a0d19-c3b3-408d-e60e-6623196fe254"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{131072: 0,\n",
              " 1: 1,\n",
              " 2: 2,\n",
              " 3: 3,\n",
              " 4: 4,\n",
              " 5: 5,\n",
              " 6: 6,\n",
              " 7: 7,\n",
              " 8: 8,\n",
              " 9: 9,\n",
              " 10: 10,\n",
              " 11: 11,\n",
              " 12: 12,\n",
              " 13: 13,\n",
              " 14: 14,\n",
              " 15: 15,\n",
              " 16: 16,\n",
              " 17: 17,\n",
              " 18: 18,\n",
              " 19: 19,\n",
              " 20: 20,\n",
              " 21: 21,\n",
              " 22: 22,\n",
              " 23: 23,\n",
              " 24: 24,\n",
              " 25: 25,\n",
              " 26: 26,\n",
              " 27: 27,\n",
              " 28: 28,\n",
              " 29: 29,\n",
              " 30: 30,\n",
              " 31: 31,\n",
              " 32: 32,\n",
              " 33: 33,\n",
              " 34: 34,\n",
              " 35: 35,\n",
              " 36: 36,\n",
              " 37: 37,\n",
              " 38: 38,\n",
              " 39: 39,\n",
              " 40: 40,\n",
              " 41: 41,\n",
              " 42: 42,\n",
              " 43: 43,\n",
              " 44: 44,\n",
              " 45: 45,\n",
              " 46: 46,\n",
              " 47: 47,\n",
              " 48: 48,\n",
              " 49: 49,\n",
              " 50: 50,\n",
              " 51: 51,\n",
              " 52: 52,\n",
              " 53: 53,\n",
              " 54: 54,\n",
              " 55: 55,\n",
              " 56: 56,\n",
              " 57: 57,\n",
              " 58: 58,\n",
              " 59: 59,\n",
              " 60: 60,\n",
              " 61: 61,\n",
              " 62: 62,\n",
              " 63: 63,\n",
              " 64: 64,\n",
              " 65: 65,\n",
              " 66: 66,\n",
              " 67: 67,\n",
              " 68: 68,\n",
              " 69: 69,\n",
              " 70: 70,\n",
              " 71: 71,\n",
              " 72: 72,\n",
              " 73: 73,\n",
              " 74: 74,\n",
              " 75: 75,\n",
              " 76: 76,\n",
              " 77: 77,\n",
              " 78: 78,\n",
              " 79: 79,\n",
              " 80: 80,\n",
              " 81: 81,\n",
              " 82: 82,\n",
              " 83: 83,\n",
              " 84: 84,\n",
              " 85: 85,\n",
              " 86: 86,\n",
              " 87: 87,\n",
              " 88: 88,\n",
              " 89: 89,\n",
              " 90: 90,\n",
              " 131162: 91,\n",
              " 92: 92,\n",
              " 93: 93,\n",
              " 94: 94,\n",
              " 95: 95,\n",
              " 96: 96,\n",
              " 97: 97,\n",
              " 98: 98,\n",
              " 99: 99,\n",
              " 100: 100,\n",
              " 101: 101,\n",
              " 102: 102,\n",
              " 103: 103,\n",
              " 104: 104,\n",
              " 105: 105,\n",
              " 106: 106,\n",
              " 107: 107,\n",
              " 108: 108,\n",
              " 109: 109,\n",
              " 110: 110,\n",
              " 111: 111,\n",
              " 112: 112,\n",
              " 113: 113,\n",
              " 114: 114,\n",
              " 115: 115,\n",
              " 116: 116,\n",
              " 117: 117,\n",
              " 118: 118,\n",
              " 119: 119,\n",
              " 120: 120,\n",
              " 121: 121,\n",
              " 122: 122,\n",
              " 123: 123,\n",
              " 124: 124,\n",
              " 125: 125,\n",
              " 126: 126,\n",
              " 127: 127,\n",
              " 128: 128,\n",
              " 129: 129,\n",
              " 130: 130,\n",
              " 131: 131,\n",
              " 132: 132,\n",
              " 133: 133,\n",
              " 134: 134,\n",
              " 135: 135,\n",
              " 136: 136,\n",
              " 137: 137,\n",
              " 138: 138,\n",
              " 139: 139,\n",
              " 140: 140,\n",
              " 141: 141,\n",
              " 142: 142,\n",
              " 143: 143,\n",
              " 144: 144,\n",
              " 145: 145,\n",
              " 146: 146,\n",
              " 147: 147,\n",
              " 148: 148,\n",
              " 149: 149,\n",
              " 150: 150,\n",
              " 151: 151,\n",
              " 152: 152,\n",
              " 153: 153,\n",
              " 154: 154,\n",
              " 155: 155,\n",
              " 156: 156,\n",
              " 157: 157,\n",
              " 158: 158,\n",
              " 159: 159,\n",
              " 160: 160,\n",
              " 161: 161,\n",
              " 162: 162,\n",
              " 163: 163,\n",
              " 164: 164,\n",
              " 165: 165,\n",
              " 166: 166,\n",
              " 167: 167,\n",
              " 168: 168,\n",
              " 169: 169,\n",
              " 170: 170,\n",
              " 171: 171,\n",
              " 172: 172,\n",
              " 173: 173,\n",
              " 174: 174,\n",
              " 175: 175,\n",
              " 176: 176,\n",
              " 177: 177,\n",
              " 178: 178,\n",
              " 179: 179,\n",
              " 180: 180,\n",
              " 181: 181,\n",
              " 182: 182,\n",
              " 183: 183,\n",
              " 184: 184,\n",
              " 185: 185,\n",
              " 186: 186,\n",
              " 187: 187,\n",
              " 188: 188,\n",
              " 189: 189,\n",
              " 190: 190,\n",
              " 191: 191,\n",
              " 192: 192,\n",
              " 193: 193,\n",
              " 194: 194,\n",
              " 195: 195,\n",
              " 196: 196,\n",
              " 197: 197,\n",
              " 198: 198,\n",
              " 199: 199,\n",
              " 200: 200,\n",
              " 201: 201,\n",
              " 202: 202,\n",
              " 203: 203,\n",
              " 204: 204,\n",
              " 205: 205,\n",
              " 206: 206,\n",
              " 207: 207,\n",
              " 208: 208,\n",
              " 209: 209,\n",
              " 210: 210,\n",
              " 211: 211,\n",
              " 212: 212,\n",
              " 213: 213,\n",
              " 214: 214,\n",
              " 215: 215,\n",
              " 216: 216,\n",
              " 217: 217,\n",
              " 218: 218,\n",
              " 219: 219,\n",
              " 220: 220,\n",
              " 222: 221,\n",
              " 223: 222,\n",
              " 224: 223,\n",
              " 225: 224,\n",
              " 226: 225,\n",
              " 227: 226,\n",
              " 228: 227,\n",
              " 229: 228,\n",
              " 230: 229,\n",
              " 231: 230,\n",
              " 232: 231,\n",
              " 233: 232,\n",
              " 234: 233,\n",
              " 235: 234,\n",
              " 236: 235,\n",
              " 237: 236,\n",
              " 238: 237,\n",
              " 239: 238,\n",
              " 240: 239,\n",
              " 241: 240,\n",
              " 242: 241,\n",
              " 243: 242,\n",
              " 244: 243,\n",
              " 245: 244,\n",
              " 246: 245,\n",
              " 247: 246,\n",
              " 248: 247,\n",
              " 249: 248,\n",
              " 250: 249,\n",
              " 251: 250,\n",
              " 252: 251,\n",
              " 253: 252,\n",
              " 254: 253,\n",
              " 255: 254,\n",
              " 256: 255,\n",
              " 257: 256,\n",
              " 258: 257,\n",
              " 259: 258,\n",
              " 260: 259,\n",
              " 261: 260,\n",
              " 262: 261,\n",
              " 263: 262,\n",
              " 264: 263,\n",
              " 265: 264,\n",
              " 266: 265,\n",
              " 267: 266,\n",
              " 268: 267,\n",
              " 269: 268,\n",
              " 270: 269,\n",
              " 271: 270,\n",
              " 272: 271,\n",
              " 273: 272,\n",
              " 274: 273,\n",
              " 275: 274,\n",
              " 276: 275,\n",
              " 277: 276,\n",
              " 278: 277,\n",
              " 279: 278,\n",
              " 280: 279,\n",
              " 281: 280,\n",
              " 282: 281,\n",
              " 283: 282,\n",
              " 284: 283,\n",
              " 285: 284,\n",
              " 286: 285,\n",
              " 287: 286,\n",
              " 288: 287,\n",
              " 289: 288,\n",
              " 290: 289,\n",
              " 291: 290,\n",
              " 292: 291,\n",
              " 293: 292,\n",
              " 294: 293,\n",
              " 295: 294,\n",
              " 296: 295,\n",
              " 297: 296,\n",
              " 298: 297,\n",
              " 299: 298,\n",
              " 300: 299,\n",
              " 301: 300,\n",
              " 302: 301,\n",
              " 303: 302,\n",
              " 304: 303,\n",
              " 305: 304,\n",
              " 306: 305,\n",
              " 307: 306,\n",
              " 308: 307,\n",
              " 309: 308,\n",
              " 310: 309,\n",
              " 311: 310,\n",
              " 312: 311,\n",
              " 313: 312,\n",
              " 314: 313,\n",
              " 315: 314,\n",
              " 316: 315,\n",
              " 317: 316,\n",
              " 318: 317,\n",
              " 319: 318,\n",
              " 320: 319,\n",
              " 321: 320,\n",
              " 322: 321,\n",
              " 324: 322,\n",
              " 325: 323,\n",
              " 326: 324,\n",
              " 327: 325,\n",
              " 328: 326,\n",
              " 329: 327,\n",
              " 330: 328,\n",
              " 331: 329,\n",
              " 332: 330,\n",
              " 333: 331,\n",
              " 334: 332,\n",
              " 335: 333,\n",
              " 336: 334,\n",
              " 337: 335,\n",
              " 338: 336,\n",
              " 339: 337,\n",
              " 340: 338,\n",
              " 341: 339,\n",
              " 342: 340,\n",
              " 343: 341,\n",
              " 344: 342,\n",
              " 345: 343,\n",
              " 346: 344,\n",
              " 347: 345,\n",
              " 348: 346,\n",
              " 349: 347,\n",
              " 350: 348,\n",
              " 351: 349,\n",
              " 352: 350,\n",
              " 353: 351,\n",
              " 354: 352,\n",
              " 355: 353,\n",
              " 356: 354,\n",
              " 357: 355,\n",
              " 358: 356,\n",
              " 359: 357,\n",
              " 360: 358,\n",
              " 361: 359,\n",
              " 362: 360,\n",
              " 363: 361,\n",
              " 364: 362,\n",
              " 365: 363,\n",
              " 366: 364,\n",
              " 367: 365,\n",
              " 368: 366,\n",
              " 369: 367,\n",
              " 370: 368,\n",
              " 371: 369,\n",
              " 372: 370,\n",
              " 373: 371,\n",
              " 374: 372,\n",
              " 375: 373,\n",
              " 376: 374,\n",
              " 377: 375,\n",
              " 378: 376,\n",
              " 379: 377,\n",
              " 380: 378,\n",
              " 381: 379,\n",
              " 382: 380,\n",
              " 383: 381,\n",
              " 384: 382,\n",
              " 385: 383,\n",
              " 386: 384,\n",
              " 387: 385,\n",
              " 388: 386,\n",
              " 389: 387,\n",
              " 390: 388,\n",
              " 391: 389,\n",
              " 392: 390,\n",
              " 393: 391,\n",
              " 394: 392,\n",
              " 395: 393,\n",
              " 396: 394,\n",
              " 397: 395,\n",
              " 398: 396,\n",
              " 399: 397,\n",
              " 400: 398,\n",
              " 401: 399,\n",
              " 402: 400,\n",
              " 403: 401,\n",
              " 404: 402,\n",
              " 405: 403,\n",
              " 406: 404,\n",
              " 407: 405,\n",
              " 408: 406,\n",
              " 409: 407,\n",
              " 410: 408,\n",
              " 411: 409,\n",
              " 412: 410,\n",
              " 413: 411,\n",
              " 414: 412,\n",
              " 415: 413,\n",
              " 416: 414,\n",
              " 417: 415,\n",
              " 418: 416,\n",
              " 419: 417,\n",
              " 420: 418,\n",
              " 421: 419,\n",
              " 422: 420,\n",
              " 423: 421,\n",
              " 424: 422,\n",
              " 425: 423,\n",
              " 426: 424,\n",
              " 427: 425,\n",
              " 428: 426,\n",
              " 429: 427,\n",
              " 430: 428,\n",
              " 431: 429,\n",
              " 432: 430,\n",
              " 433: 431,\n",
              " 434: 432,\n",
              " 435: 433,\n",
              " 436: 434,\n",
              " 437: 435,\n",
              " 438: 436,\n",
              " 439: 437,\n",
              " 440: 438,\n",
              " 441: 439,\n",
              " 442: 440,\n",
              " 443: 441,\n",
              " 444: 442,\n",
              " 445: 443,\n",
              " 446: 444,\n",
              " 447: 445,\n",
              " 448: 446,\n",
              " 449: 447,\n",
              " 450: 448,\n",
              " 451: 449,\n",
              " 452: 450,\n",
              " 453: 451,\n",
              " 454: 452,\n",
              " 455: 453,\n",
              " 456: 454,\n",
              " 457: 455,\n",
              " 458: 456,\n",
              " 459: 457,\n",
              " 460: 458,\n",
              " 461: 459,\n",
              " 462: 460,\n",
              " 463: 461,\n",
              " 464: 462,\n",
              " 465: 463,\n",
              " 466: 464,\n",
              " 467: 465,\n",
              " 468: 466,\n",
              " 469: 467,\n",
              " 470: 468,\n",
              " 471: 469,\n",
              " 472: 470,\n",
              " 473: 471,\n",
              " 474: 472,\n",
              " 475: 473,\n",
              " 476: 474,\n",
              " 477: 475,\n",
              " 478: 476,\n",
              " 479: 477,\n",
              " 480: 478,\n",
              " 481: 479,\n",
              " 482: 480,\n",
              " 483: 481,\n",
              " 484: 482,\n",
              " 485: 483,\n",
              " 486: 484,\n",
              " 487: 485,\n",
              " 488: 486,\n",
              " 489: 487,\n",
              " 490: 488,\n",
              " 491: 489,\n",
              " 492: 490,\n",
              " 493: 491,\n",
              " 494: 492,\n",
              " 495: 493,\n",
              " 496: 494,\n",
              " 497: 495,\n",
              " 498: 496,\n",
              " 499: 497,\n",
              " 500: 498,\n",
              " 501: 499,\n",
              " 502: 500,\n",
              " 503: 501,\n",
              " 504: 502,\n",
              " 505: 503,\n",
              " 506: 504,\n",
              " 507: 505,\n",
              " 508: 506,\n",
              " 509: 507,\n",
              " 510: 508,\n",
              " 511: 509,\n",
              " 512: 510,\n",
              " 513: 511,\n",
              " 514: 512,\n",
              " 515: 513,\n",
              " 516: 514,\n",
              " 517: 515,\n",
              " 518: 516,\n",
              " 519: 517,\n",
              " 520: 518,\n",
              " 521: 519,\n",
              " 522: 520,\n",
              " 523: 521,\n",
              " 524: 522,\n",
              " 525: 523,\n",
              " 526: 524,\n",
              " 527: 525,\n",
              " 528: 526,\n",
              " 529: 527,\n",
              " 530: 528,\n",
              " 531: 529,\n",
              " 532: 530,\n",
              " 533: 531,\n",
              " 534: 532,\n",
              " 535: 533,\n",
              " 536: 534,\n",
              " 537: 535,\n",
              " 538: 536,\n",
              " 539: 537,\n",
              " 540: 538,\n",
              " 541: 539,\n",
              " 542: 540,\n",
              " 543: 541,\n",
              " 544: 542,\n",
              " 545: 543,\n",
              " 546: 544,\n",
              " 547: 545,\n",
              " 548: 546,\n",
              " 549: 547,\n",
              " 550: 548,\n",
              " 551: 549,\n",
              " 552: 550,\n",
              " 553: 551,\n",
              " 554: 552,\n",
              " 555: 553,\n",
              " 556: 554,\n",
              " 558: 555,\n",
              " 559: 556,\n",
              " 560: 557,\n",
              " 561: 558,\n",
              " 562: 559,\n",
              " 563: 560,\n",
              " 564: 561,\n",
              " 565: 562,\n",
              " 566: 563,\n",
              " 567: 564,\n",
              " 568: 565,\n",
              " 569: 566,\n",
              " 570: 567,\n",
              " 571: 568,\n",
              " 572: 569,\n",
              " 573: 570,\n",
              " 574: 571,\n",
              " 575: 572,\n",
              " 576: 573,\n",
              " 577: 574,\n",
              " 579: 575,\n",
              " 580: 576,\n",
              " 581: 577,\n",
              " 582: 578,\n",
              " 583: 579,\n",
              " 584: 580,\n",
              " 585: 581,\n",
              " 586: 582,\n",
              " 587: 583,\n",
              " 588: 584,\n",
              " 589: 585,\n",
              " 590: 586,\n",
              " 591: 587,\n",
              " 592: 588,\n",
              " 593: 589,\n",
              " 594: 590,\n",
              " 595: 591,\n",
              " 596: 592,\n",
              " 597: 593,\n",
              " 598: 594,\n",
              " 599: 595,\n",
              " 600: 596,\n",
              " 601: 597,\n",
              " 602: 598,\n",
              " 603: 599,\n",
              " 604: 600,\n",
              " 605: 601,\n",
              " 606: 602,\n",
              " 607: 603,\n",
              " 608: 604,\n",
              " 609: 605,\n",
              " 610: 606,\n",
              " 611: 607,\n",
              " 612: 608,\n",
              " 613: 609,\n",
              " 614: 610,\n",
              " 615: 611,\n",
              " 616: 612,\n",
              " 617: 613,\n",
              " 618: 614,\n",
              " 619: 615,\n",
              " 620: 616,\n",
              " 621: 617,\n",
              " 623: 618,\n",
              " 624: 619,\n",
              " 625: 620,\n",
              " 626: 621,\n",
              " 627: 622,\n",
              " 628: 623,\n",
              " 629: 624,\n",
              " 630: 625,\n",
              " 631: 626,\n",
              " 632: 627,\n",
              " 633: 628,\n",
              " 634: 629,\n",
              " 635: 630,\n",
              " 636: 631,\n",
              " 637: 632,\n",
              " 638: 633,\n",
              " 639: 634,\n",
              " 640: 635,\n",
              " 641: 636,\n",
              " 642: 637,\n",
              " 643: 638,\n",
              " 644: 639,\n",
              " 645: 640,\n",
              " 647: 641,\n",
              " 648: 642,\n",
              " 649: 643,\n",
              " 650: 644,\n",
              " 651: 645,\n",
              " 652: 646,\n",
              " 653: 647,\n",
              " 654: 648,\n",
              " 655: 649,\n",
              " 656: 650,\n",
              " 657: 651,\n",
              " 658: 652,\n",
              " 659: 653,\n",
              " 660: 654,\n",
              " 661: 655,\n",
              " 662: 656,\n",
              " 663: 657,\n",
              " 664: 658,\n",
              " 665: 659,\n",
              " 666: 660,\n",
              " 667: 661,\n",
              " 668: 662,\n",
              " 670: 663,\n",
              " 671: 664,\n",
              " 672: 665,\n",
              " 673: 666,\n",
              " 674: 667,\n",
              " 675: 668,\n",
              " 676: 669,\n",
              " 678: 670,\n",
              " 679: 671,\n",
              " 680: 672,\n",
              " 681: 673,\n",
              " 682: 674,\n",
              " 683: 675,\n",
              " 684: 676,\n",
              " 685: 677,\n",
              " 687: 678,\n",
              " 688: 679,\n",
              " 690: 680,\n",
              " 691: 681,\n",
              " 692: 682,\n",
              " 693: 683,\n",
              " 694: 684,\n",
              " 695: 685,\n",
              " 696: 686,\n",
              " 697: 687,\n",
              " 698: 688,\n",
              " 699: 689,\n",
              " 700: 690,\n",
              " 701: 691,\n",
              " 702: 692,\n",
              " 703: 693,\n",
              " 704: 694,\n",
              " 705: 695,\n",
              " 706: 696,\n",
              " 707: 697,\n",
              " 708: 698,\n",
              " 709: 699,\n",
              " 710: 700,\n",
              " 711: 701,\n",
              " 712: 702,\n",
              " 713: 703,\n",
              " 714: 704,\n",
              " 715: 705,\n",
              " 716: 706,\n",
              " 717: 707,\n",
              " 718: 708,\n",
              " 719: 709,\n",
              " 720: 710,\n",
              " 721: 711,\n",
              " 722: 712,\n",
              " 723: 713,\n",
              " 724: 714,\n",
              " 725: 715,\n",
              " 726: 716,\n",
              " 727: 717,\n",
              " 728: 718,\n",
              " 729: 719,\n",
              " 730: 720,\n",
              " 731: 721,\n",
              " 732: 722,\n",
              " 733: 723,\n",
              " 734: 724,\n",
              " 735: 725,\n",
              " 736: 726,\n",
              " 737: 727,\n",
              " 738: 728,\n",
              " 739: 729,\n",
              " 741: 730,\n",
              " 742: 731,\n",
              " 743: 732,\n",
              " 744: 733,\n",
              " 745: 734,\n",
              " 746: 735,\n",
              " 747: 736,\n",
              " 748: 737,\n",
              " 749: 738,\n",
              " 750: 739,\n",
              " 751: 740,\n",
              " 752: 741,\n",
              " 753: 742,\n",
              " 754: 743,\n",
              " 755: 744,\n",
              " 756: 745,\n",
              " 757: 746,\n",
              " 758: 747,\n",
              " 759: 748,\n",
              " 760: 749,\n",
              " 761: 750,\n",
              " 762: 751,\n",
              " 763: 752,\n",
              " 764: 753,\n",
              " 765: 754,\n",
              " 766: 755,\n",
              " 767: 756,\n",
              " 768: 757,\n",
              " 769: 758,\n",
              " 770: 759,\n",
              " 771: 760,\n",
              " 772: 761,\n",
              " 773: 762,\n",
              " 774: 763,\n",
              " 775: 764,\n",
              " 776: 765,\n",
              " 777: 766,\n",
              " 778: 767,\n",
              " 779: 768,\n",
              " 780: 769,\n",
              " 781: 770,\n",
              " 782: 771,\n",
              " 783: 772,\n",
              " 784: 773,\n",
              " 785: 774,\n",
              " 786: 775,\n",
              " 787: 776,\n",
              " 788: 777,\n",
              " 789: 778,\n",
              " 790: 779,\n",
              " 791: 780,\n",
              " 792: 781,\n",
              " 793: 782,\n",
              " 794: 783,\n",
              " 795: 784,\n",
              " 796: 785,\n",
              " 797: 786,\n",
              " 798: 787,\n",
              " 799: 788,\n",
              " 800: 789,\n",
              " 801: 790,\n",
              " 802: 791,\n",
              " 803: 792,\n",
              " 804: 793,\n",
              " 805: 794,\n",
              " 806: 795,\n",
              " 807: 796,\n",
              " 808: 797,\n",
              " 809: 798,\n",
              " 810: 799,\n",
              " 812: 800,\n",
              " 813: 801,\n",
              " 814: 802,\n",
              " 815: 803,\n",
              " 816: 804,\n",
              " 818: 805,\n",
              " 819: 806,\n",
              " 820: 807,\n",
              " 821: 808,\n",
              " 822: 809,\n",
              " 823: 810,\n",
              " 824: 811,\n",
              " 825: 812,\n",
              " 826: 813,\n",
              " 827: 814,\n",
              " 828: 815,\n",
              " 829: 816,\n",
              " 830: 817,\n",
              " 831: 818,\n",
              " 832: 819,\n",
              " 833: 820,\n",
              " 834: 821,\n",
              " 835: 822,\n",
              " 836: 823,\n",
              " 837: 824,\n",
              " 838: 825,\n",
              " 839: 826,\n",
              " 840: 827,\n",
              " 841: 828,\n",
              " 842: 829,\n",
              " 843: 830,\n",
              " 844: 831,\n",
              " 845: 832,\n",
              " 846: 833,\n",
              " 847: 834,\n",
              " 848: 835,\n",
              " 849: 836,\n",
              " 850: 837,\n",
              " 851: 838,\n",
              " 852: 839,\n",
              " 853: 840,\n",
              " 854: 841,\n",
              " 855: 842,\n",
              " 856: 843,\n",
              " 857: 844,\n",
              " 858: 845,\n",
              " 859: 846,\n",
              " 860: 847,\n",
              " 861: 848,\n",
              " 862: 849,\n",
              " 864: 850,\n",
              " 865: 851,\n",
              " 866: 852,\n",
              " 867: 853,\n",
              " 868: 854,\n",
              " 869: 855,\n",
              " 870: 856,\n",
              " 871: 857,\n",
              " 872: 858,\n",
              " 873: 859,\n",
              " 874: 860,\n",
              " 875: 861,\n",
              " 876: 862,\n",
              " 877: 863,\n",
              " 878: 864,\n",
              " 879: 865,\n",
              " 880: 866,\n",
              " 881: 867,\n",
              " 882: 868,\n",
              " 884: 869,\n",
              " 885: 870,\n",
              " 886: 871,\n",
              " 887: 872,\n",
              " 888: 873,\n",
              " 889: 874,\n",
              " 890: 875,\n",
              " 891: 876,\n",
              " 892: 877,\n",
              " 893: 878,\n",
              " 894: 879,\n",
              " 895: 880,\n",
              " 896: 881,\n",
              " 897: 882,\n",
              " 898: 883,\n",
              " 899: 884,\n",
              " 900: 885,\n",
              " 901: 886,\n",
              " 902: 887,\n",
              " 903: 888,\n",
              " 904: 889,\n",
              " 905: 890,\n",
              " 906: 891,\n",
              " 907: 892,\n",
              " 908: 893,\n",
              " 909: 894,\n",
              " 910: 895,\n",
              " 911: 896,\n",
              " 912: 897,\n",
              " 913: 898,\n",
              " 914: 899,\n",
              " 915: 900,\n",
              " 916: 901,\n",
              " 917: 902,\n",
              " 918: 903,\n",
              " 919: 904,\n",
              " 920: 905,\n",
              " 921: 906,\n",
              " 922: 907,\n",
              " 923: 908,\n",
              " 924: 909,\n",
              " 925: 910,\n",
              " 926: 911,\n",
              " 927: 912,\n",
              " 928: 913,\n",
              " 929: 914,\n",
              " 930: 915,\n",
              " 931: 916,\n",
              " 932: 917,\n",
              " 933: 918,\n",
              " 934: 919,\n",
              " 935: 920,\n",
              " 936: 921,\n",
              " 937: 922,\n",
              " 938: 923,\n",
              " 939: 924,\n",
              " 940: 925,\n",
              " 941: 926,\n",
              " 942: 927,\n",
              " 943: 928,\n",
              " 944: 929,\n",
              " 945: 930,\n",
              " 946: 931,\n",
              " 947: 932,\n",
              " 948: 933,\n",
              " 949: 934,\n",
              " 950: 935,\n",
              " 951: 936,\n",
              " 952: 937,\n",
              " 953: 938,\n",
              " 954: 939,\n",
              " 955: 940,\n",
              " 956: 941,\n",
              " 957: 942,\n",
              " 958: 943,\n",
              " 959: 944,\n",
              " 960: 945,\n",
              " 961: 946,\n",
              " 962: 947,\n",
              " 963: 948,\n",
              " 964: 949,\n",
              " 965: 950,\n",
              " 966: 951,\n",
              " 967: 952,\n",
              " 968: 953,\n",
              " 969: 954,\n",
              " 970: 955,\n",
              " 971: 956,\n",
              " 972: 957,\n",
              " 973: 958,\n",
              " 974: 959,\n",
              " 975: 960,\n",
              " 976: 961,\n",
              " 977: 962,\n",
              " 979: 963,\n",
              " 980: 964,\n",
              " 981: 965,\n",
              " 982: 966,\n",
              " 983: 967,\n",
              " 984: 968,\n",
              " 985: 969,\n",
              " 986: 970,\n",
              " 987: 971,\n",
              " 988: 972,\n",
              " 989: 973,\n",
              " 990: 974,\n",
              " 991: 975,\n",
              " 992: 976,\n",
              " 993: 977,\n",
              " 994: 978,\n",
              " 996: 979,\n",
              " 997: 980,\n",
              " 998: 981,\n",
              " 999: 982,\n",
              " 1000: 983,\n",
              " 1001: 984,\n",
              " 1002: 985,\n",
              " 1003: 986,\n",
              " 1004: 987,\n",
              " 1005: 988,\n",
              " 1006: 989,\n",
              " 1007: 990,\n",
              " 1008: 991,\n",
              " 1009: 992,\n",
              " 1010: 993,\n",
              " 1011: 994,\n",
              " 1012: 995,\n",
              " 1013: 996,\n",
              " 1014: 997,\n",
              " 1015: 998,\n",
              " 1016: 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add them to the data frame\n",
        "# takes awhile\n",
        "df['movie_idx'] = df.apply(lambda row: movie2idx[row.movieId], axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0h0GsMWKlhnM",
        "outputId": "80f68cd7-16bc-4cc5-a742-c20f7b15f7b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          userId  movieId  rating            timestamp  movie_idx\n",
              "0              0        2     3.5  2005-04-02 23:53:47          2\n",
              "1              0       29     3.5  2005-04-02 23:31:16         29\n",
              "2              0       32     3.5  2005-04-02 23:33:39         32\n",
              "3              0       47     3.5  2005-04-02 23:32:07         47\n",
              "4              0       50     3.5  2005-04-02 23:29:40         50\n",
              "...          ...      ...     ...                  ...        ...\n",
              "20000258  138492    68954     4.5  2009-11-13 15:42:00      13821\n",
              "20000259  138492    69526     4.5  2009-12-03 18:31:48      13929\n",
              "20000260  138492    69644     3.0  2009-12-07 18:10:57      13942\n",
              "20000261  138492    70286     5.0  2009-11-13 15:42:24      14060\n",
              "20000262  138492    71619     2.5  2009-10-17 20:25:36      14344\n",
              "\n",
              "[20000263 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75dc3e86-f289-462f-a53c-4ff71a41304e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>movie_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000258</th>\n",
              "      <td>138492</td>\n",
              "      <td>68954</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-11-13 15:42:00</td>\n",
              "      <td>13821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000259</th>\n",
              "      <td>138492</td>\n",
              "      <td>69526</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-12-03 18:31:48</td>\n",
              "      <td>13929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000260</th>\n",
              "      <td>138492</td>\n",
              "      <td>69644</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2009-12-07 18:10:57</td>\n",
              "      <td>13942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000261</th>\n",
              "      <td>138492</td>\n",
              "      <td>70286</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2009-11-13 15:42:24</td>\n",
              "      <td>14060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000262</th>\n",
              "      <td>138492</td>\n",
              "      <td>71619</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2009-10-17 20:25:36</td>\n",
              "      <td>14344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000263 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75dc3e86-f289-462f-a53c-4ff71a41304e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75dc3e86-f289-462f-a53c-4ff71a41304e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75dc3e86-f289-462f-a53c-4ff71a41304e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['timestamp'])\n",
        "df.to_csv('edited_rating.csv', index=False)"
      ],
      "metadata": {
        "id": "VwbsdZrylvmW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "lGSaHTTsm5Hs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"original dataframe size:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k15tN46inbbS",
        "outputId": "6e781240-7a08-4b29-bc36-38e605b04732"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original dataframe size: 20000263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = df.userId.max() + 1 # number of users\n",
        "M = df.movie_idx.max() + 1 # number of movies\n",
        "\n",
        "user_ids_count = Counter(df.userId)\n",
        "movie_ids_count = Counter(df.movie_idx)"
      ],
      "metadata": {
        "id": "nD8mDyGinemH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of users and movies we would like to keep\n",
        "n = 10000\n",
        "m = 2000\n",
        "\n",
        "user_ids = [u for u, c in user_ids_count.most_common(n)]\n",
        "movie_ids = [m for m, c in movie_ids_count.most_common(m)]"
      ],
      "metadata": {
        "id": "hMMDFDCanjmS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df[df.userId.isin(user_ids) & df.movie_idx.isin(movie_ids)].copy()"
      ],
      "metadata": {
        "id": "B1Bg6NRXnoyM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to remake user ids and movie ids since they are no longer sequential\n",
        "new_user_id_map = {}\n",
        "i = 0\n",
        "for old in user_ids:\n",
        "  new_user_id_map[old] = i\n",
        "  i += 1\n",
        "print(\"i:\", i)\n",
        "\n",
        "new_movie_id_map = {}\n",
        "j = 0\n",
        "for old in movie_ids:\n",
        "  new_movie_id_map[old] = j\n",
        "  j += 1\n",
        "print(\"j:\", j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTl5UIDhnuJS",
        "outputId": "462cb7eb-9f2c-4944-ae6b-9e61ce926468"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 10000\n",
            "j: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Setting new ids\")\n",
        "df_small.loc[:, 'userId'] = df_small.apply(lambda row: new_user_id_map[row.userId], axis=1)\n",
        "df_small.loc[:, 'movie_idx'] = df_small.apply(lambda row: new_movie_id_map[row.movie_idx], axis=1)\n",
        "# df_small.drop(columns=['userId', 'movie_idx'])\n",
        "# df_small.rename(index=str, columns={'new_userId': 'userId', 'new_movie_idx': 'movie_idx'})\n",
        "print(\"max user id:\", df_small.userId.max())\n",
        "print(\"max movie id:\", df_small.movie_idx.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvz3y8xIn1u9",
        "outputId": "ae1bb172-f456-40e5-9cb0-d870eb18e7e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting new ids\n",
            "max user id: 9999\n",
            "max movie id: 1999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"small dataframe size:\", len(df_small))\n",
        "df_small.to_csv('/content/drive/MyDrive/Recommender_Systems/small_rating.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC7ynyE4n72m",
        "outputId": "c4631a34-22c0-4f7b-b4cb-18526cb6528f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small dataframe size: 5392025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# load in the data\n",
        "# https://www.kaggle.com/grouplens/movielens-20m-dataset\n",
        "df = df_small\n",
        "\n",
        "N = df.userId.max() + 1 # number of users\n",
        "M = df.movie_idx.max() + 1 # number of movies\n",
        "\n",
        "# split into train and test\n",
        "df = shuffle(df)\n",
        "cutoff = int(0.8*len(df))\n",
        "df_train = df.iloc[:cutoff]\n",
        "df_test = df.iloc[cutoff:]"
      ],
      "metadata": {
        "id": "-17mA1CYolzu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a dictionary to tell us which users have rated which movies\n",
        "user2movie = {}\n",
        "# a dicationary to tell us which movies have been rated by which users\n",
        "movie2user = {}\n",
        "# a dictionary to look up ratings\n",
        "usermovie2rating = {}\n",
        "print(\"Calling: update_user2movie_and_movie2user\")\n",
        "count = 0\n",
        "def update_user2movie_and_movie2user(row):\n",
        "  global count\n",
        "  count += 1\n",
        "  if count % 100000 == 0:\n",
        "    print(\"processed: %.3f\" % (float(count)/cutoff))\n",
        "\n",
        "  i = int(row.userId)\n",
        "  j = int(row.movie_idx)\n",
        "  if i not in user2movie:\n",
        "    user2movie[i] = [j]\n",
        "  else:\n",
        "    user2movie[i].append(j)\n",
        "\n",
        "  if j not in movie2user:\n",
        "    movie2user[j] = [i]\n",
        "  else:\n",
        "    movie2user[j].append(i)\n",
        "\n",
        "  usermovie2rating[(i,j)] = row.rating\n",
        "df_train.apply(update_user2movie_and_movie2user, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCAbxD_WpC9-",
        "outputId": "b889414c-034b-432f-c761-2190775b984b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: update_user2movie_and_movie2user\n",
            "processed: 0.023\n",
            "processed: 0.046\n",
            "processed: 0.070\n",
            "processed: 0.093\n",
            "processed: 0.116\n",
            "processed: 0.139\n",
            "processed: 0.162\n",
            "processed: 0.185\n",
            "processed: 0.209\n",
            "processed: 0.232\n",
            "processed: 0.255\n",
            "processed: 0.278\n",
            "processed: 0.301\n",
            "processed: 0.325\n",
            "processed: 0.348\n",
            "processed: 0.371\n",
            "processed: 0.394\n",
            "processed: 0.417\n",
            "processed: 0.440\n",
            "processed: 0.464\n",
            "processed: 0.487\n",
            "processed: 0.510\n",
            "processed: 0.533\n",
            "processed: 0.556\n",
            "processed: 0.580\n",
            "processed: 0.603\n",
            "processed: 0.626\n",
            "processed: 0.649\n",
            "processed: 0.672\n",
            "processed: 0.695\n",
            "processed: 0.719\n",
            "processed: 0.742\n",
            "processed: 0.765\n",
            "processed: 0.788\n",
            "processed: 0.811\n",
            "processed: 0.835\n",
            "processed: 0.858\n",
            "processed: 0.881\n",
            "processed: 0.904\n",
            "processed: 0.927\n",
            "processed: 0.950\n",
            "processed: 0.974\n",
            "processed: 0.997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16859307    None\n",
              "16683255    None\n",
              "15671005    None\n",
              "15826318    None\n",
              "6990383     None\n",
              "            ... \n",
              "19431425    None\n",
              "13069521    None\n",
              "13820706    None\n",
              "9540343     None\n",
              "8813971     None\n",
              "Length: 4313620, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test ratings dictionary\n",
        "usermovie2rating_test = {}\n",
        "print(\"Calling: update_usermovie2rating_test\")\n",
        "count = 0\n",
        "def update_usermovie2rating_test(row):\n",
        "  global count\n",
        "  count += 1\n",
        "  if count % 100000 == 0:\n",
        "    print(\"processed: %.3f\" % (float(count)/len(df_test)))\n",
        "\n",
        "  i = int(row.userId)\n",
        "  j = int(row.movie_idx)\n",
        "  usermovie2rating_test[(i,j)] = row.rating\n",
        "df_test.apply(update_usermovie2rating_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABb8J6OLp9lJ",
        "outputId": "7c767005-bdad-45d5-ef87-3865263aeb66"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: update_usermovie2rating_test\n",
            "processed: 0.093\n",
            "processed: 0.185\n",
            "processed: 0.278\n",
            "processed: 0.371\n",
            "processed: 0.464\n",
            "processed: 0.556\n",
            "processed: 0.649\n",
            "processed: 0.742\n",
            "processed: 0.835\n",
            "processed: 0.927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15533435    None\n",
              "446321      None\n",
              "287968      None\n",
              "11088202    None\n",
              "4478395     None\n",
              "            ... \n",
              "8881002     None\n",
              "7576606     None\n",
              "8184947     None\n",
              "5003726     None\n",
              "12479839    None\n",
              "Length: 1078405, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Recommender_Systems/user2movie.json', 'wb') as f:\n",
        "  pickle.dump(user2movie, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Recommender_Systems/movie2user.json', 'wb') as f:\n",
        "  pickle.dump(movie2user, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Recommender_Systems/usermovie2rating.json', 'wb') as f:\n",
        "  pickle.dump(usermovie2rating, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Recommender_Systems/usermovie2rating_test.json', 'wb') as f:\n",
        "  pickle.dump(usermovie2rating_test, f)"
      ],
      "metadata": {
        "id": "Eqm1EOUsq0rU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import os"
      ],
      "metadata": {
        "id": "VXYns-EPrxIi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('user2movie.json', 'rb') as f:\n",
        "  user2movie = pickle.load(f)\n",
        "\n",
        "with open('movie2user.json', 'rb') as f:\n",
        "  movie2user = pickle.load(f)\n",
        "\n",
        "with open('usermovie2rating.json', 'rb') as f:\n",
        "  usermovie2rating = pickle.load(f)\n",
        "\n",
        "with open('usermovie2rating_test.json', 'rb') as f:\n",
        "  usermovie2rating_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "cOKSXSkZsPQf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = np.max(list(user2movie.keys())) + 1\n",
        "# the test set may contain movies the train set doesn't have data on\n",
        "m1 = np.max(list(movie2user.keys()))\n",
        "m2 = np.max([m for (u, m), r in usermovie2rating_test.items()])\n",
        "M = max(m1, m2) + 1\n",
        "print(\"N:\", N, \"M:\", M)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PNRPfZYsShN",
        "outputId": "017bd857-98ba-46df-fc2a-15b58640586d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N: 10000 M: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize variables\n",
        "K = 10 # latent dimensionality\n",
        "W = np.random.randn(N, K)\n",
        "b = np.zeros(N)\n",
        "U = np.random.randn(M, K)\n",
        "c = np.zeros(M)\n",
        "mu = np.mean(list(usermovie2rating.values()))\n",
        "\n",
        "# prediction[i,j] = W[i].dot(U[j]) + b[i] + c.T[j] + mu"
      ],
      "metadata": {
        "id": "QEgLNm5Yslhn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(d):\n",
        "  # d: (user_id, movie_id) -> rating\n",
        "  N = float(len(d))\n",
        "  sse = 0\n",
        "  for k, r in d.items():\n",
        "    i, j = k\n",
        "    p = W[i].dot(U[j]) + b[i] + c[j] + mu\n",
        "    sse += (p - r)*(p - r)\n",
        "  return sse / N"
      ],
      "metadata": {
        "id": "z4hHNvMPs4Oz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the parameters\n",
        "epochs = 25\n",
        "reg =20. # regularization penalty\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "for epoch in range(epochs):\n",
        "  print(\"epoch:\", epoch)\n",
        "  epoch_start = datetime.now()\n",
        "  # perform updates\n",
        "\n",
        "  # update W and b\n",
        "  t0 = datetime.now()\n",
        "  for i in range(N):\n",
        "    # for W\n",
        "    matrix = np.eye(K) * reg\n",
        "    vector = np.zeros(K)\n",
        "\n",
        "    # for b\n",
        "    bi = 0\n",
        "    for j in user2movie[i]:\n",
        "      r = usermovie2rating[(i,j)]\n",
        "      matrix += np.outer(U[j], U[j])\n",
        "      vector += (r - b[i] - c[j] - mu)*U[j]\n",
        "      bi += (r - W[i].dot(U[j]) - c[j] - mu)\n",
        "\n",
        "    # set the updates\n",
        "    W[i] = np.linalg.solve(matrix, vector)\n",
        "    b[i] = bi / (len(user2movie[i]) + reg)\n",
        "\n",
        "    if i % (N//10) == 0:\n",
        "      print(\"i:\", i, \"N:\", N)\n",
        "  print(\"updated W and b:\", datetime.now() - t0)\n",
        "\n",
        "  # update U and c\n",
        "  t0 = datetime.now()\n",
        "  for j in range(M):\n",
        "    # for U\n",
        "    matrix = np.eye(K) * reg\n",
        "    vector = np.zeros(K)\n",
        "\n",
        "    # for c\n",
        "    cj = 0\n",
        "    try:\n",
        "      for i in movie2user[j]:\n",
        "        r = usermovie2rating[(i,j)]\n",
        "        matrix += np.outer(W[i], W[i])\n",
        "        vector += (r - b[i] - c[j] - mu)*W[i]\n",
        "        cj += (r - W[i].dot(U[j]) - b[i] - mu)\n",
        "\n",
        "      # set the updates\n",
        "      U[j] = np.linalg.solve(matrix, vector)\n",
        "      c[j] = cj / (len(movie2user[j]) + reg)\n",
        "\n",
        "      if j % (M//10) == 0:\n",
        "        print(\"j:\", j, \"M:\", M)\n",
        "    except KeyError:\n",
        "      # possible not to have any ratings for a movie\n",
        "      pass\n",
        "  print(\"updated U and c:\", datetime.now() - t0)\n",
        "  print(\"epoch duration:\", datetime.now() - epoch_start)\n",
        "\n",
        "\n",
        "  # store train loss\n",
        "  t0 = datetime.now()\n",
        "  train_losses.append(get_loss(usermovie2rating))\n",
        "\n",
        "  # store test loss\n",
        "  test_losses.append(get_loss(usermovie2rating_test))\n",
        "  print(\"calculate cost:\", datetime.now() - t0)\n",
        "  print(\"train loss:\", train_losses[-1])\n",
        "  print(\"test loss:\", test_losses[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEDiw9EBtYpX",
        "outputId": "bed3abf0-7ced-4f63-a70d-6e48dbb4199c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:16.172871\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:17.552304\n",
            "epoch duration: 0:02:33.726866\n",
            "calculate cost: 0:00:10.638101\n",
            "train loss: 0.6929160152027116\n",
            "test loss: 0.702261859785165\n",
            "epoch: 1\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.100047\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:16.303519\n",
            "epoch duration: 0:02:31.404995\n",
            "calculate cost: 0:00:10.549080\n",
            "train loss: 0.5705659618586357\n",
            "test loss: 0.5963080368756314\n",
            "epoch: 2\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.873455\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:16.435156\n",
            "epoch duration: 0:02:32.309968\n",
            "calculate cost: 0:00:10.635169\n",
            "train loss: 0.5344491532150788\n",
            "test loss: 0.5632028303399306\n",
            "epoch: 3\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.415068\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:16.636372\n",
            "epoch duration: 0:02:32.052825\n",
            "calculate cost: 0:00:10.611906\n",
            "train loss: 0.5232121395807696\n",
            "test loss: 0.551738950743062\n",
            "epoch: 4\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:17.988480\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:20.618688\n",
            "epoch duration: 0:02:38.609890\n",
            "calculate cost: 0:00:11.202754\n",
            "train loss: 0.5179879120282058\n",
            "test loss: 0.5465475187991614\n",
            "epoch: 5\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:20.602103\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:20.933752\n",
            "epoch duration: 0:02:41.537913\n",
            "calculate cost: 0:00:11.366606\n",
            "train loss: 0.5153748316037603\n",
            "test loss: 0.5438157676553189\n",
            "epoch: 6\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:21.590894\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:19.580647\n",
            "epoch duration: 0:02:41.173554\n",
            "calculate cost: 0:00:12.187038\n",
            "train loss: 0.513884060552131\n",
            "test loss: 0.5423655872738692\n",
            "epoch: 7\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:19.253455\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:19.170603\n",
            "epoch duration: 0:02:38.425073\n",
            "calculate cost: 0:00:12.712940\n",
            "train loss: 0.513010182993279\n",
            "test loss: 0.5414672792279347\n",
            "epoch: 8\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:14.757792\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:14.689007\n",
            "epoch duration: 0:02:29.448084\n",
            "calculate cost: 0:00:10.549887\n",
            "train loss: 0.5124429226154742\n",
            "test loss: 0.5409238823419468\n",
            "epoch: 9\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.348266\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:15.835850\n",
            "epoch duration: 0:02:31.186997\n",
            "calculate cost: 0:00:10.519576\n",
            "train loss: 0.5120745068571085\n",
            "test loss: 0.5405363605232638\n",
            "epoch: 10\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.842567\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:14.708813\n",
            "epoch duration: 0:02:30.552881\n",
            "calculate cost: 0:00:10.558957\n",
            "train loss: 0.5118047279174811\n",
            "test loss: 0.5402660189557696\n",
            "epoch: 11\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.353799\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:15.464083\n",
            "epoch duration: 0:02:30.820196\n",
            "calculate cost: 0:00:10.523981\n",
            "train loss: 0.5116033806744165\n",
            "test loss: 0.5400414512677607\n",
            "epoch: 12\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:16.025543\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:16.970529\n",
            "epoch duration: 0:02:32.998591\n",
            "calculate cost: 0:00:10.500395\n",
            "train loss: 0.5114327082812182\n",
            "test loss: 0.5398563839704277\n",
            "epoch: 13\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.177064\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:15.136967\n",
            "epoch duration: 0:02:30.317189\n",
            "calculate cost: 0:00:10.458579\n",
            "train loss: 0.511284814094513\n",
            "test loss: 0.5396833664537323\n",
            "epoch: 14\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:14.861973\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:14.615072\n",
            "epoch duration: 0:02:29.477477\n",
            "calculate cost: 0:00:10.588603\n",
            "train loss: 0.5111456387231298\n",
            "test loss: 0.5395247595950841\n",
            "epoch: 15\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:15.919707\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:16.667223\n",
            "epoch duration: 0:02:32.588500\n",
            "calculate cost: 0:00:10.462601\n",
            "train loss: 0.5110157109545973\n",
            "test loss: 0.539372199268413\n",
            "epoch: 16\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:17.570893\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:14.222001\n",
            "epoch duration: 0:02:31.795388\n",
            "calculate cost: 0:00:10.493526\n",
            "train loss: 0.5108918385983843\n",
            "test loss: 0.5392310315197136\n",
            "epoch: 17\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:17.047444\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:15.815952\n",
            "epoch duration: 0:02:32.866374\n",
            "calculate cost: 0:00:10.486347\n",
            "train loss: 0.510777799253402\n",
            "test loss: 0.5391009443597128\n",
            "epoch: 18\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:16.884951\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:16.182473\n",
            "epoch duration: 0:02:33.068986\n",
            "calculate cost: 0:00:10.497053\n",
            "train loss: 0.5106741171924684\n",
            "test loss: 0.5389862905631594\n",
            "epoch: 19\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:17.952065\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:14.881464\n",
            "epoch duration: 0:02:32.834887\n",
            "calculate cost: 0:00:10.487819\n",
            "train loss: 0.5105835891826638\n",
            "test loss: 0.5388875908377448\n",
            "epoch: 20\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:17.874684\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:15.155229\n",
            "epoch duration: 0:02:33.032800\n",
            "calculate cost: 0:00:10.566895\n",
            "train loss: 0.5105059557424715\n",
            "test loss: 0.5388056898232173\n",
            "epoch: 21\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:14.252253\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:07.706471\n",
            "epoch duration: 0:02:21.959928\n",
            "calculate cost: 0:00:10.386562\n",
            "train loss: 0.5104414569735778\n",
            "test loss: 0.5387393929896713\n",
            "epoch: 22\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:07.116989\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:06.658637\n",
            "epoch duration: 0:02:13.777797\n",
            "calculate cost: 0:00:11.955088\n",
            "train loss: 0.5103884521083886\n",
            "test loss: 0.5386869535091819\n",
            "epoch: 23\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:06.258169\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:06.707871\n",
            "epoch duration: 0:02:12.968085\n",
            "calculate cost: 0:00:10.377298\n",
            "train loss: 0.5103457573416806\n",
            "test loss: 0.5386463789612856\n",
            "epoch: 24\n",
            "i: 0 N: 10000\n",
            "i: 1000 N: 10000\n",
            "i: 2000 N: 10000\n",
            "i: 3000 N: 10000\n",
            "i: 4000 N: 10000\n",
            "i: 5000 N: 10000\n",
            "i: 6000 N: 10000\n",
            "i: 7000 N: 10000\n",
            "i: 8000 N: 10000\n",
            "i: 9000 N: 10000\n",
            "updated W and b: 0:01:08.121982\n",
            "j: 0 M: 2000\n",
            "j: 200 M: 2000\n",
            "j: 400 M: 2000\n",
            "j: 600 M: 2000\n",
            "j: 800 M: 2000\n",
            "j: 1000 M: 2000\n",
            "j: 1200 M: 2000\n",
            "j: 1400 M: 2000\n",
            "j: 1600 M: 2000\n",
            "j: 1800 M: 2000\n",
            "updated U and c: 0:01:06.741808\n",
            "epoch duration: 0:02:14.865093\n",
            "calculate cost: 0:00:10.363520\n",
            "train loss: 0.5103114633287787\n",
            "test loss: 0.5386153083442005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(\"train losses:\", train_losses)\n",
        "print(\"test losses:\", test_losses)\n",
        "\n",
        "# plot losses\n",
        "plt.plot(train_losses, label=\"train loss\")\n",
        "plt.plot(test_losses, label=\"test loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Ipj_-086yFW8",
        "outputId": "06189b5b-398e-4f36-ebc6-38d36ec7aa67"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train losses: [0.6929160152027116, 0.5705659618586357, 0.5344491532150788, 0.5232121395807696, 0.5179879120282058, 0.5153748316037603, 0.513884060552131, 0.513010182993279, 0.5124429226154742, 0.5120745068571085, 0.5118047279174811, 0.5116033806744165, 0.5114327082812182, 0.511284814094513, 0.5111456387231298, 0.5110157109545973, 0.5108918385983843, 0.510777799253402, 0.5106741171924684, 0.5105835891826638, 0.5105059557424715, 0.5104414569735778, 0.5103884521083886, 0.5103457573416806, 0.5103114633287787]\n",
            "test losses: [0.702261859785165, 0.5963080368756314, 0.5632028303399306, 0.551738950743062, 0.5465475187991614, 0.5438157676553189, 0.5423655872738692, 0.5414672792279347, 0.5409238823419468, 0.5405363605232638, 0.5402660189557696, 0.5400414512677607, 0.5398563839704277, 0.5396833664537323, 0.5395247595950841, 0.539372199268413, 0.5392310315197136, 0.5391009443597128, 0.5389862905631594, 0.5388875908377448, 0.5388056898232173, 0.5387393929896713, 0.5386869535091819, 0.5386463789612856, 0.5386153083442005]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXmZG1LnCGUv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}